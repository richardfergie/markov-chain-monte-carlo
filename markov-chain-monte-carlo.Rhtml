<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <title>Markov Chain Monte Carlo</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <script src="https://code.jquery.com/jquery-2.1.3.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }});
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script src="/js/r-tutorial.js"></script>
  <script type="text/javascript" async src="//platform.twitter.com/widgets.js"></script>
</head>
<body>
  <!--begin.rcode echo=FALSE
      opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE,fig.width=12,fig.height=8,upload.fun = image_uri)
      set.seed(125124)
      ho0 <- knit_hooks$get('output')

      knit_hooks$set(
         output = function(x, options) {
            paste0("<div class='wrapoutput'>", ho0(x,options), "</div>")
    }
  )
      end.rcode -->
  <div class="container">
    <h1>Markov Chain Monte Carlo</h1>
    <p>
      An introduction to Markov Chain Monte Carlo, supporting presentations
      given at MeasureCamp, Web Analytics Wednesday and PPC Chat Live.
    </p>
    <p>Last updated on <!--rinline format(Sys.time(), "%A %d %B %Y") --></p>
    <h2>Introduction and Motivation</h2>
    <p>Suppose you have the following data and what to plot a straight line of
      best fit:</p>
    <!--begin.rcode echo=TRUE
      raw <- data.frame(x=c(1,2,3,4,5,6),
                        y=c(4.06,3.264,16.376,15.638,14.076,16.571)
                       )
      kable(raw)
             end.rcode-->
    <!--begin.rcode echo=TRUE
      library(ggplot2)
      rawplot <- ggplot(raw,aes(x=x,y=y)) +
         geom_point(size=5) +
         xlim(c(0,7)) +
         ylim(c(0,20)) +
         theme_minimal()
      rawplot
    end.rcode-->
    <p>How do you actually do this?</p>
    <p>In real life, you use a built in function (`lm` in R or something else in
    Excel) and you don't really worry too much about what is happening behind
      the scenes.</p>
    <!--begin.rcode echo=TRUE
      fit <- lm(y~x,data=raw)
      fit
             end.rcode-->
    <!--begin.rcode echo=TRUE
      bflineplot <- rawplot + geom_abline(slope=fit$coefficients[2],
                            intercept=fit$coefficients[1],
                            color="blue",size=3)
      bflineplot
    end.rcode-->
    <p>But what exactly is going on here?</p>
    <p>I'm going to show you one way of doing this so that I can later contrast
      it with the Markov Chain Monte Carlo way of doing things.</p>
    <h4>What is the line of best fit?</h4>
    <p>For this demonstration I'm going to say that the line of best fit is the
    straight line that minimises the sum of the squares of the errors. There are
      other possible definitions here.</p>
    <!--begin.rcode echo=TRUE
       bflineplot + geom_segment(x=raw$x,
                                 y=raw$y,
                                 yend=fit$coefficients[2]*raw$x+fit$coefficients[1],
                                 xend=raw$x,
                                 color="green",
                                 size=2)
    end.rcode-->
    <p>The line of best fit is the straight line that minimises the sum of the
      squared length of all the green lines.</p>
    <p>For those of you who speak R, this might be easier to understand with the
      following function that calculates the error we are trying to minimise.</p>
    <!-- begin.rcode echo=TRUE
       calculate_error <- function(slope,intercept) {
          predicted_y <- slope*raw$x + intercept
          squared_error <- (predicted_y - raw$y)^2
          return( sum(squared_error) )
       }
                           end.rcode-->
    <p>This can be plotted (contour plot because plotting 3D seems hard!)</p>
    <!--begin.rcode echo=TRUE
      slopes <- seq(0,7,0.1)
      intercepts <- seq(-1,9,0.1)
      plot3Ddata <- expand.grid(slopes,intercepts)
      names(plot3Ddata) <- c("slope","intercept")
      plot3Ddata$error <- sapply(1:nrow(plot3Ddata), function(x) calculate_error(plot3Ddata$slope[x],plot3Ddata$intercept[x]))
      contourplot <- ggplot(plot3Ddata,aes(x=slope,y=intercept,z=error)) +
                          geom_contour(binwidth=10) +
                          theme_minimal()
      contourplot
                          end.rcode-->
    <p>This shows that the error is minimised with a slope value somewhere
    between about 2.5 and 3 and an intercept somewhere between about 1.5 and
      2.6.</p>
    <p>In this case, we can determine the value analytically [warning:
      maths]</p>
    <small>The important thing isn't that you follow the derivation below. The
    point is that the derivation exists and that a direct solution can be found.</small>
    <p>
      $$ error(slope,intercept) = \sum_{i=1}^{i=n} (y_{i} - (slope \circ x_{i} +
      intercept))^2 $$
      $$ \frac{\partial error}{\partial slope} = -2 \sum_{i=1}^{i=n} (y_{i} - (slope \circ x_{i} +
      intercept)) \circ x_{i} $$
      $$ \frac{\partial error}{\partial intercept} = -2 \sum_{i=1}^{i=n} (y_{i} - (slope \circ x_{i} +
      intercept)) $$
      At the minimum, both of these are zero. Rearranging the second of the
      above derivatives gives
      $$ intercept = \frac{\sum y_i - slope \circ \sum x_i}{n}  $$
      $$ intercept = \bar{y} - slope \circ \bar{x} $$
      Where $\bar{x}$ and $\bar{y}$ are the means of the $x_i$ and $y_i$
      respectively.<br/>
      Then substitute back into the slope equation
      $$ 0 = \sum y_i x_i - slope \sum x_{i}^2 - intercept \sum x_i $$
      $$ 0 = \sum y_i x_i - slope \sum x_{i}^2 - (\bar{y} - slope \circ \bar{x})
      \sum x_i $$
      Rearranging for slope
      $$ slope = \frac{\sum x_i y_i - \bar{y} \sum x_{i}}{\sum x_i^{2} - \bar{x}
      \sum x_i} $$
    </p>
    <p>In R:
      <!--begin.rcode echo=TRUE
        s <- (sum(raw$x*raw$y)-mean(raw$y)*sum(raw$x)) /
             (sum(raw$x*raw$x) - mean(raw$x)*sum(raw$x))
        i <- mean(raw$y) - s * mean(raw$x)
        kable(data.frame(Slope=s,Intercept=i))
             end.rcode-->
      <!--begin.rcode echo=TRUE
        contourplot + geom_point(x=s,y=i,colour="green",size=3)
      end.rcode-->
    </p>
    <p>
      This approach is great if you want a single answer that minimises the
      squared error. And in some circumstances this should be exactly what you
      want.
    </p>
    <p>
      But in other circumstances questions like "what is the probability that
      the slope is greater than 1.4?" or "how likely is it that the intercept is
      greater than zero?" are more appropriate.
    </p>
    <p>(The slope question might occur if you are investigating the relationship
    between media spend and revenue - here the slope is the estimated increase
    in revenue for a unit increase in spend. If the channel has a slope greater
    than the slope of the next best channel then it should get more budget. Of
      course, a <em>linear</em> model is probably not appropriate here.)</p>
    <h3>Random Processes</h3>
    <p>To attack the problem from this direction we need to rephrase it: rather
    than trying to find the straight line that minimises the squared errors we
      are looking for something else.</p>
    <p>If we knew the probability distributions of the model parameters we would
      be able to answer our questions. In mathy notation we want to find
      $$ P(model | data) $$
      Where $data$ is the stuff we observed.
    </p>
    <p>
      We can think of our data being generated by a <em>random process</em>:
      $$ error_i \sim N(0,\sigma) $$
      $$ y_i = slope \circ x_i + intercept + error_i $$
    </p>
    <p>
      What this says is that the $y_i$ are generated from the $x_i$ using $y =
      slope \circ x + intercept$ with an extra error term.</p>
    <p>We don't know exactly what the error is, but we assume that it is
    normally distributed with mean 0 (so positive and negative errors are
      equally likely) and unknown standard deviation $\sigma$.
    </p>
    <p>
      With this model we can directly answer questions like "if the slope was 3,
      the intercept 0 and the standard deviation 1, what is the chance we
      observe y=5 at x=2?"
      <small>Again, the actual maths isn't important here. The important thing
      is that you realise it is quite easy to calculate the probability of
      observing some specific data given a model.</small>
      $$ P(y=5 | x=2, slope=3, intercept=0, \sigma=1) = P(error = -1) $$
      Because $ 3 \circ 2 + 0 = 6 $ so the error must be -1
      $$ P(error = -1) = P(N(0,1)=-1) $$
      Where $N(0,1)$ is the normal distribution density function
      $$ P(error = -1) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}} $$
      $$ P(error = -1) = 0.242 $$
      I have abused notation and concepts when talking about continuous
      distributions. I think I'm on safe enough ground here to get away with
      it but please let me know if you get trapped in a paradox as a result of
      this.
    </p>
    <p> So we can find
      $$ P(data | model) $$
      fairly easily, using the kind of techniques you might have learned at
      school (A-level maybe?)
    </p>
    <h4>Enter Bayes</h4>
    <p>Bayes' Theorem tells us that:
      $$ P(model | data) = \frac{P(data | model)P(model)}{P(data)} $$
      Here, $P(model)$ is our prior probability of the model and $P(data)$ is
      the probability of observing the data independently of any model.
    </p>
    <p>
      The important thing to note here is that $P(data)$ is constant over
      different models. So
      $$ P(model | data) \propto P(data | model)P(model) $$
      That is, the probability of the model given the data is proportional to
      the probability of the data given the model multiplied by our prior on the
      model.
    </p>
    <p>So if we know how to calculate $P(data | model)$ (and generally we do,
    see example above and more examples below) we can calculate something that
      is proportional to $P(model | data)$
    </p>
    <p>
      What <strong>Markov Chain Monte Carlo</strong> gives us is a method of
      sampling from a distribution without needing to know the density function
      of the distribution; instead we only need something that is proportional
      to the density function.
    </p>
    <p>
      Which means we can use Markov Chain Monte Carlo on $P(data |
      model)P(model)$ and the output will be samples from $P(model | data)$
    </p>
    <p>Then we can use the samples to see the distributions of the different
      parameters.</p>
    <h3>Example</h3>
    <p>Remember our data from earlier:</p>
    <!--begin.rcode
      kable(raw)
    end.rcode-->
    <p>We can make a function over our model parameters (slope, intercept,
    standard deviation of the random error) that tells us
      $P(data|slope,intercept,\sigma)$
    </p>
    <!--begin.rcode echo=TRUE
      likelihood <- function(slope,intercept,sd) {
         err <- raw$y - (slope*raw$x + intercept)
         ls <- dnorm(err,mean=0,sd=sd)
         return(prod(ls))
      }
               end.rcode-->
    <p>If you play around with a few values here you see that the likelihoods
    are very, very small. To stop over/under flow when computers calculate this
    kind of thing it is normal to use the log of the likelihood function
      instead.
    </p>
    <!--begin.rcode echo=TRUE
      logLikelihood <- function(parameters) {
         slope <- parameters[1]
         intercept <- parameters[2]
         sd <- parameters[3]
         if(sd <= 0) { return(-Inf) }
         err <- raw$y - (slope*raw$x + intercept)
         ls <- dnorm(err,mean=0,sd=sd,log=TRUE)
         return(sum(ls))
         }
               end.rcode-->
   <p>We can then use the mcmc library to get our samples:</p>
   <!--begin.rcode echo=TRUE
     library(mcmc)
     start <- c(0,0,1)
     out <- metrop(logLikelihood,start,1000)
            end.rcode-->
   <p>Plot the results against the data</p>
   <!--begin.rcode echo=TRUE
      trace <- as.data.frame(out$batch)
      names(trace) <- c("slope","intercept","sd")
      rawplot + geom_abline(data=trace,
                            aes(slope=slope,intercept=intercept),
                            alpha=0.1,
                            colour="green")
                      end.rcode-->
   <p>
     As you can see, this is all over the place. What does this tell us?  
   </p>
   <p>
     It tells us that we can't be very certain of our slope or intercept
     estimates. We can get more insight here by plotting the marginal
     distributions.
   </p>
   <!--begin.rcode echo=TRUE
     ggplot(trace,aes(x=slope)) + geom_histogram() + theme_minimal()
   end.rcode-->
    <p>
      Values for the slope are spread between 0 and 4 and...</p>
   <!--begin.rcode echo=TRUE
     ggplot(trace,aes(x=intercept)) + geom_histogram() + theme_minimal()
   end.rcode-->
    <p>values for the intercept are spread between 0 and 10!</p>
    <p>Back to our example questions:
      <ol>
        <li>What is the probability that the slope is greater than 1.4?</li>
        <li>How likely is it that the intercept is greater than zero?</li>
      </ol>
      We can answer these just by examining the samples:
      <!--begin.rcode echo=TRUE
      df <- data.frame(Question1=1-ecdf(trace$slope)(1.4),
                       Question2=1-ecdf(trace$intercept)(0)
            )
      kable(df)
            end.rcode-->
    <h3>Example 2</h3>
    <p>Let's try with another example with a slightly more certain result (and
    where we know the true model parameters</p>
    <!--begin.rcode echo=TRUE
      x <- seq(from=1,to=6,by=1)
      y <- 3*x+0+rnorm(6,mean=0,sd=0.5)
      raw2 <- data.frame(x=x,
                         y=y
                        )
      raw2plot <- ggplot(raw2,aes(x=x,y=y)) +
                     geom_point(size=5) +
                     xlim(c(0,7)) +
                     ylim(c(0,20)) +
                     theme_minimal()
      raw2plot
      end.rcode-->
    <p>Again, we need to make a likelihood function:
    <!--begin.rcode echo=TRUE
    logLikelihood <- function(parameters) {
     slope <- parameters[1]
     intercept <- parameters[2]
     sd <- parameters[3]
     if(sd <= 0) { return(-Inf) }
     err <- raw2$y - (slope*raw2$x + intercept)
     ls <- dnorm(err,mean=0,sd=sd,log=TRUE)
     return(sum(ls))
     }
           end.rcode-->
    </p>
    <p>After which, we can do our sampling:</p>
    <!--begin.rcode echo=TRUE
      out <- metrop(logLikelihood,start,1000)
      trace <- as.data.frame(out$batch)
      names(trace) <- c("slope","intercept","sd")
      raw2plot + geom_abline(data=trace,
                         aes(slope=slope,intercept=intercept),
                         alpha=0.1,
                         colour="green")
                      end.rcode-->
    <p>Here we are much more sure about what the slope and intercept might be -
      the distributions are much "narrower"</p>
    <!--begin.rcode echo=TRUE
     slopetrace <- ggplot(trace,aes(x=slope)) + geom_histogram() +
      theme_minimal()
     slopetrace
   end.rcode-->
   <!--begin.rcode echo=TRUE
     intercepttrace <- ggplot(trace,aes(x=intercept)) + geom_histogram() +
      theme_minimal()
     intercepttrace
   end.rcode-->
   <!--begin.rcode echo=TRUE
     # recall that the true value is 3
     mean(trace$slope)
   end.rcode-->
    <p>
      Not bad! And we could probably do better by increasing the number of
     iterations
    </p>
    <h2>Sampling Methods</h2>
    <p>Unfortunately the above has glossed over some interesting details of why
      all this works:
      <ol>
        <li>How are the samples generated?</li>
        <li>Why is it that we can sample from the actual distributions when we
          only know something that is proportional to the density function?</li>
      </ol>
      I'm not going to touch the second one of these at all and I'm not going to
      go into the first one in much depth. I'm just getting this deep into the
      subject matter myself at the moment and I fear I couldn't do it justice.
    </p>
    <h3>Metropolis-Hastings</h3>
    The examples above (using the `metrop` function) use a sampling methodology
    called "Metropolis-Hastings".
    <p>Advantages of Metropolis-Hastings:
      <ul>
        <li>Fast generation of samples</li>
        <li>Fairly simple</li>
        <li>Doesn't require computing derivatives</li>
      </ul>
      Disadvantages:
      <ul>
        <li>Requires manual "tuning" of parameters</li>
        <li>Can struggle with "skewed" and "stretched" distributions (known
          as <em>anisotropic <d>$1</d>istributions</em>. See
          <a href="http://jtobin.ca/flat-mcmc/">here</a> for some visualisations
          of this problem.
        </li>
        <li>No cool points from the MCMC community for using this</li>
      </ul>
      Metropolis-Hastings goes on
      a <a href="https://en.wikipedia.org/wiki/Random_walk">random walk</a>
      around the parameter space. At each stage, a new position is proposed and
      then the Markov Chain moves there or stays in the same spot depending on
      how likely the proposed position is compared to the current position.</p>
    <p>
      The main thing to "tune" for Metropolis-Hastings is how far it moves at
      each step. If it tries to move too far then the proposed position is
      likely to be rejected and the chain will stay in one place.
    </p>
    <p>
      If it doesn't move far enough then the chain will stay roughly in the same
      place and not explore the whole distribution.
    </p>
    <p>We must also specify where the chain starts from (the variable `start` in
      the examples above)</p>
    <p>Picking bad values for these things can lead to bad results as we see in
      the below examples:</p>
    <!--begin.rcode echo=TRUE
    # start position miles away from true values
    out <- metrop(logLikelihood,c(100,0,1),1000,scale=1)
    trace2 <- as.data.frame(out$batch)
    names(trace2) <- c("slope","intercept","sd")
    raw2plot  + geom_abline(data=trace2,
                     aes(slope=slope,intercept=intercept),
                     alpha=0.1,
                     colour="green")
                    end.rcode-->
    <!--begin.rcode echo=TRUE
    # huge step size
    out <- metrop(logLikelihood,c(1,0,1),1000,scale=10)
    trace3 <- as.data.frame(out$batch)
    names(trace3) <- c("slope","intercept","sd")
    raw2plot  + geom_abline(data=trace3,
                     aes(slope=slope,intercept=intercept),
                     alpha=0.5,
                     colour="green")
                    end.rcode-->
   <p>
    Tuning can be tricky - particularly because in some cases you don't even
    know what good looks like. Trying to tune something when you don't know if it
    is getting better can be hard - there are a few MCMC specific techniques for
    this that you can lookup elsewhere, but all of these are of the form "if it
    is bad then you will see this". None of them assert that "if you don't see
    this then it is all good".
   </p>
   <h3>NUTS</h3>
   <p>The "No U-Turn Sampler" doesn't require as much tuning as
     Metropolis-Hastings <strong>and</strong> it has a specialised model
     specification format that means you don't need to write your own likelihood
     functions!
   </p>
   <!--begin.rcode echo=TRUE, cache=TRUE, results='hide'
     library(rstan)
     rstan_options(auto_write = TRUE)
     options(mc.cores = parallel::detectCores())

     model <- "data {
                 int<lower=0>N; //the number of observations
                 real x[N];
                 real y[N];
               }
               parameters {
                 real slope;
                 real intercept;
                 real<lower=0> sigma;
               }
               transformed parameters {
                 real err[N];
                 for (i in 1:N) {
                   err[i] <- y[i] - slope * x[i] - intercept;
                 }
               }
               model {
                 err ~ normal(0,sigma);
               }"
     fit <- stan(model_code=model,data=d,iter=1000,chains=4)
            end.rcode-->
    <p>There is a nice library for exploring stan chains called "shinystan"
      <!--begin.rcode echo=TRUE, eval=FALSE
        library(shinystan)
        launch_shinystan(fit)
        # browser opens for you to explore model
      end.rcode-->
    <p>To get some output in this document I will use ggplot</p>
    <!--begin.rcode echo=TRUE
      samples <- extract(fit)
      samples <- as.data.frame(samples)
      raw2plot  + geom_abline(data=samples,
                 aes(slope=slope,intercept=intercept),
                 alpha=0.01,
                 colour="green")
      end.rcode-->
   <p>Compare how "smooth" the plots of the marginal distributions are compared
     to our first effort with Metropolis-Hastings; this is because there was no
     attempt at tuning with the first demo.</p>
   <!--begin.rcode echo=FALSE, results='hide'
     multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
                  end.rcode-->
    <!--begin.rcode echo=FALSE
      slopetracemh <- slopetrace +
                      ggtitle("Slope: Metropolis-Hastings") +
                      xlim(c(0,5))
      intercepttracemh <- intercepttrace +
                            ggtitle("Intercept: Metropolis-Hastings") +
                            xlim(c(-5,2.5))
      slopetracenuts <- ggplot(samples,aes(x=slope)) + geom_histogram() +
                          theme_minimal() +
                          ggtitle("Slope: NUTS") +
                          xlim(c(0,5))
      intercepttracenuts <- ggplot(samples,aes(x=intercept)) + geom_histogram() +
                          theme_minimal() +
                          ggtitle("Intercept: NUTS") +
                          xlim(c(-5,2.5))
      # multiplot from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
      multiplot(slopetracemh,
                intercepttracemh,
                slopetracenuts,
                intercepttracenuts,
                cols=2)
                            end.rcode-->
    <p>For the rest of this document, I'm going to use stan for the examples to
      save the hassle of tuning and figuring out likelihood functions.</p>
    <h2>Case Studies</h2>
    <p>
      These case studies use made up data. They should be seen as a study of
      the method and process rather than the results.
    </p>
    <h3>Brand Search Uplift</h3>
    <p>
      A client with <em>extremely</em> good brand recognition and little or no
      SERP competition was naturally concerned about the amount of money being
      spent on brand clicks (~40% of their budget).
    </p>
    <p>
      Their main investors also had a very switched on analytics guy who was
      asking tricky questions around incremental value. We had to run an
      experiment to figure out what was going on.
    </p>
    <h4>Experiment Setup</h4>
    <ol>
      <li>
        Find two cities with similar volume. The volumes don't have to be
        identical (which is good, because they never are) but there is an important
        model assumption later that the volumes are proportional to each other. We
        used Edinburgh and Glasgow for this test
      </li>
      <li>
        Pause the ads in one location for a week. Don't change anything in the
        other location<br/>
        We chose a week here to align with the length of the buying cycle. More
        discussion on this below.
      </li>
      <li>
        Reactivate the paused ads and pause ads in the other location. Do this
        for a week as well.
      </li>
      <li>
        Analyse the results
      </li>
    </ol>
    <h4>Results Analysis</h4>
    <p>Suppose the results looked a bit like the following:
      <!--begin.rcode echo=TRUE
         rawBrand <- data.frame(Edinburgh=c(332,258,219,240,183,162,241,209,209,214,200,202,178,221),
                                Glasgow=c(381,252,281,243,237,192,227,293,263,224,223,249,223,271),
                                Week=c(1,1,1,1,1,1,1,2,2,2,2,2,2,2)
                               )
         kable(rawBrand)
                     end.rcode-->
      <!--begin.rcode echo=TRUE
         library(reshape2)
         rawBrand$day <- as.integer(rownames(rawBrand))
         tall <- melt(rawBrand,id.vars=c("day","Week"))
         ggplot(tall,aes(x=day,y=value,color=variable)) + geom_line() +
                 theme_minimal() +
                 scale_color_discrete(name="City")
                 end.rcode-->
      It looks like there is a change is volume across the two weeks the effects
      both cities. We will need to take this into account in our analysis
      otherwise our conclusions might be because there was lower volume in week
      two which has nothing to do with the experimental changes made.
                 </p>
    <!--begin.rcode echo=TRUE, cache=TRUE, results='hide'
    model <- "data {
                int<lower=1> N; // number of days of data
                real<lower=0,upper=1> geo1[N]; // results for geo1
                real<lower=0,upper=1> geo2[N]; // results for geo2
                int<lower=0,upper=1> status[N]; // whether ads are off or on in geo1
              }
              parameters {
                real<lower=0,upper=1> oncapture; // capture when ads on
                real<lower=0,upper=1> offcapture; // capture when ads off
                real<lower=0> geo2multiplier[N]; // on day i the volume in geo2 is geo2multiplier[i]*geo1
                real<lower=0> geo2multiplier_mean; // mean of the above
                real<lower=0> sdev;
              }
              transformed parameters {
                real<lower=-1> uplift;
                uplift <- oncapture/offcapture - 1;
              }
              model {
              for (i in 1:N) {
    
                // what is the difference in volume today between geo1 and geo2?
                geo2multiplier[i] ~ normal(geo2multiplier_mean,0.1);
  
                if (status[i]==1) {
                  // then ads on in geo1 and off in geo2
                  geo1[i] ~ normal(oncapture,sdev);
                  // scale geo2 by geo2multiplier
                  geo2[i] ~ normal(offcapture*geo2multiplier[i],sdev*geo2multiplier[i]);
                }
                else {
                  // ads off in geo1 and on in geo2
                  geo2[i] ~ normal(oncapture*geo2multiplier[i],sdev*geo2multiplier[i]);
                  geo1[i] ~ normal(offcapture,sdev);
                }
              }
            }"
      
    d <- list(N=14,
              geo1 = rawBrand$Edinburgh/max(rawBrand$Edinburgh,rawBrand$Glasgow),
              geo2 = rawBrand$Glasgow/max(rawBrand$Edinburgh,rawBrand$Glasgow),
              status = c(1,1,1,1,1,1,1,0,0,0,0,0,0,0)
             )
    brandupliftfit <- stan(model_code=model,data=d,iter=10000,chains=4)
           end.rcode-->
    <p>
      The parameter of interest is `uplift`. Let us see what that looks like:
    </p>
    <!--begin.rcode echo=TRUE
       samples <- extract(brandupliftfit)
       samples <- as.data.frame(samples)
       ggplot(samples,aes(x=uplift)) + geom_histogram() + theme_minimal()
       end.rcode-->
    <p>
      The percentage uplift looks like it is somewhere between 0% and 20% (this
      is not good!)
    </p>
    <!--begin.rcode echo=TRUE
      kable(quantile(samples$uplift,probs=seq(from=0,to=1,by=0.1)))
    end.rcode-->
    <p>The median is about 6%</p>
    <p>
      This is a bit different from asking if the answer is statistically
      significant. To do this you need to define a null hypothesis and this is
      hard to do in a good way here.
    </p>
    <p>
      Instead we can ask things like "how likely is it that the uplift is
      greater than 0%?" (about 80%) or "how likely is it that the uplift is
      greater than 20%?" (less than 10%). These questions correspond more
      closely with the types of things that businesses usually ask.
    </p>
    <h3>Ad Testing</h3>
    <p>
      There are plenty of online tools for telling you whether to stop or
      continue an ad test. Let's ignore flaws in the experiment setup here and
      look at another problem that responds well to this angle of attack.
    </p>
    <p>
      One problem that sometimes happens with ad testing is that people want to
      test multiple ads at once. <a href="https://xkcd.com/882/">XKCD</a>
      illustrates this issue quite nicely. The common way to solve this is to
      use
      the <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferroni
        correction</a> but this is an inelegant fudge (in my humble opinion).
    </p>
    <p>
      Using MCMC methods we can directly calculate the probability that a
      particular ad is the best out of a group. [NB. I think it is also possible
      to do this analytically].
    </p>
   <!--begin.rcode echo=TRUE, cache=TRUE, results='hide'
   model <- "data {
               int<lower=2> N; // number of adverts
               int<lower=0> clicks[N]; // number of clicks
               int<lower=0> impressions[N]; // number of impressions
             }
             parameters {
               real<lower=0,upper=1> ctr[N]; // ctr for each advert
             }
             model {
               clicks ~ binomial(impressions,ctr);
             }"
            
   d <- list(N=3,
             clicks=c(5,15,0),
             impressions=c(100,100,20)
             )
        
   adsfit <-  stan(model_code=model,data=d,iter=10000,chains=4,seed=152)
              end.rcode-->
   <p>Maybe it would be better to use a transformed parameter to calculate the
   percentage chance that ad 1 is best directly within stan. But it is easy
     enough to do this afterwards in R:
   </p>
   <!--begin.rcode echo=TRUE
   samples <- extract(adsfit)
   ctr <- as.data.frame(samples$ctr)
   ctr$V1best <- (ctr$V1 > ctr$V2) & (ctr$V1 > ctr$V3)
   ctr$V2best <- (ctr$V2 > ctr$V1) & (ctr$V2 > ctr$V3)
   ctr$V3best <- (ctr$V3 > ctr$V1) & (ctr$V3 > ctr$V2)
   res <- data.frame(Ad1=sum(ctr$V1best)/nrow(ctr),
                     Ad2=sum(ctr$V2best)/nrow(ctr),
                     Ad3=sum(ctr$V3best)/nrow(ctr)
                     )
   kable(res)
   end.rcode-->
   <p>
     So ad 2 (15 clicks from 100 impressions) is 95% likely to be the best. (I
     just made up the click/impression numbers - that the figure is 95% is pure
     coincidence and nothing to do with common p value levels.
   </p>
    <p>
      You can read more about this approach
      in <a href="http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf">Why
      We (Usually) Don't Have to Worry About Multiple Comparisons</a> which also
      talks about using another assumption in the model - that the true click
      through rates of the adverts are likely to be similar.
      </p>
  </div>
</body>
